{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import src.invariant.invariant\n",
    "import src.instrumentor.variable\n",
    "from src.instrumentor.variable import VariableInstance\n",
    "from src.invariant.invariant import SingleInvariantConstant, MultiInvariantConsistency\n",
    "\n",
    "# reload the invariant module\n",
    "import importlib\n",
    "importlib.reload(src.invariant.invariant)\n",
    "importlib.reload(src.instrumentor.variable)\n",
    "from src.instrumentor.variable import VariableInstance\n",
    "from src.invariant.invariant import SingleInvariantConstant, MultiInvariantConsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736348_140359961978688_trace.log', '/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736346_140282190907200_trace.log', '/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736344_140505828259648_trace.log', '/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736343_140216820397888_trace.log', '/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736345_140158616139584_trace.log', '/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736350_139924523960128_trace.log', '/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736349_140620820686656_trace.log', '/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing/736347_140014710134592_trace.log']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 328553/2118043 [00:03<00:22, 79285.65it/s] Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f8713f6f3d0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuxuan/miniconda3/envs/deepspeed-yuxuan/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "100%|██████████| 2118043/2118043 [00:23<00:00, 89659.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.3.input_layernorm.bias 23\n",
      "module.3.input_layernorm.weight 1\n",
      "module.3.mlp.dense_4h_to_h.bias 23\n",
      "module.3.mlp.dense_4h_to_h.weight 23\n",
      "module.3.mlp.dense_h_to_4h.bias 23\n",
      "module.3.mlp.dense_h_to_4h.weight 23\n",
      "module.3.post_attention_layernorm.bias 23\n",
      "module.3.post_attention_layernorm.weight 1\n",
      "module.3.self_attention.dense.bias 23\n",
      "module.3.self_attention.dense.weight 23\n",
      "module.3.self_attention.query_key_value.bias 23\n",
      "module.3.self_attention.query_key_value.weight 23\n",
      "module.4.input_layernorm.bias 23\n",
      "module.4.input_layernorm.weight 1\n",
      "module.4.mlp.dense_4h_to_h.bias 23\n",
      "module.4.mlp.dense_4h_to_h.weight 23\n",
      "module.4.mlp.dense_h_to_4h.bias 23\n",
      "module.4.mlp.dense_h_to_4h.weight 23\n",
      "module.4.post_attention_layernorm.bias 23\n",
      "module.4.post_attention_layernorm.weight 1\n",
      "module.4.self_attention.dense.bias 23\n",
      "module.4.self_attention.dense.weight 23\n",
      "module.4.self_attention.query_key_value.bias 23\n",
      "module.4.self_attention.query_key_value.weight 23\n",
      "module.5.input_layernorm.bias 23\n",
      "module.5.input_layernorm.weight 1\n",
      "module.5.mlp.dense_4h_to_h.bias 23\n",
      "module.5.mlp.dense_4h_to_h.weight 23\n",
      "module.5.mlp.dense_h_to_4h.bias 23\n",
      "module.5.mlp.dense_h_to_4h.weight 23\n",
      "module.5.post_attention_layernorm.bias 23\n",
      "module.5.post_attention_layernorm.weight 1\n",
      "module.5.self_attention.dense.bias 23\n",
      "module.5.self_attention.dense.weight 23\n",
      "module.5.self_attention.query_key_value.bias 23\n",
      "module.5.self_attention.query_key_value.weight 23\n",
      "module.6.input_layernorm.bias 23\n",
      "module.6.input_layernorm.weight 1\n",
      "module.6.mlp.dense_4h_to_h.bias 23\n",
      "module.6.mlp.dense_4h_to_h.weight 23\n",
      "module.6.mlp.dense_h_to_4h.bias 23\n",
      "module.6.mlp.dense_h_to_4h.weight 23\n",
      "module.6.post_attention_layernorm.bias 23\n",
      "module.6.post_attention_layernorm.weight 1\n",
      "module.6.self_attention.dense.bias 23\n",
      "module.6.self_attention.dense.weight 23\n",
      "module.6.self_attention.query_key_value.bias 23\n",
      "module.6.self_attention.query_key_value.weight 23\n",
      "module.8.bias 23\n",
      "module.8.weight 1\n",
      "module.tied_modules.embed.position_embeddings.weight 23\n",
      "module.tied_modules.embed.word_embeddings.weight 23\n"
     ]
    }
   ],
   "source": [
    "# trace loading process\n",
    "path_to_traces = \"/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing\"\n",
    "\n",
    "trace_paths = [os.path.join(path_to_traces, f) for f in os.listdir(path_to_traces) if f.endswith(\"_trace.log\")]\n",
    "print(trace_paths)\n",
    "\n",
    "with open(trace_paths[0], \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "import tqdm, json, pandas as pd\n",
    "traces = []\n",
    "for trace in tqdm.tqdm(lines):\n",
    "    if not trace.startswith(\"{\"):\n",
    "        # heuristics to skip non-json lines\n",
    "        continue\n",
    "    try:\n",
    "        traces.append(json.loads(trace))\n",
    "    except:\n",
    "        print(trace)\n",
    "        raise\n",
    "\n",
    "traces_df = pd.DataFrame(traces)\n",
    "traces_state_change = traces_df[(traces_df[\"type\"] == \"state_change\")]\n",
    "trace_state_dump = traces_df[(traces_df[\"type\"] == \"state_dump\")]\n",
    "# split the traces by name\n",
    "traces_by_name = {}\n",
    "for name, group in traces_state_change.groupby(\"name\"):\n",
    "    traces_by_name[name] = group.reset_index(drop=True)\n",
    "    print(name, len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'same': { 'name': 'module.3.mlp.dense_h_to_4h.bias',\n",
      "            'properties__backward_hooks': None,\n",
      "            'properties__base': None,\n",
      "            'properties__cdata': 1161366720,\n",
      "            'properties__grad_fn': None,\n",
      "            'properties__has_symbolic_sizes_strides': False,\n",
      "            'properties__hp_mapping': None,\n",
      "            'properties__post_accumulate_grad_hooks': None,\n",
      "            'properties__python_dispatch': False,\n",
      "            'properties__version': 1,\n",
      "            'properties_ds_pipe_replicated': False,\n",
      "            'properties_grad_fn': None,\n",
      "            'properties_is_cpu': False,\n",
      "            'properties_is_cuda': True,\n",
      "            'properties_is_ipu': False,\n",
      "            'properties_is_leaf': True,\n",
      "            'properties_is_meta': False,\n",
      "            'properties_is_mkldnn': False,\n",
      "            'properties_is_mps': False,\n",
      "            'properties_is_mtia': False,\n",
      "            'properties_is_nested': False,\n",
      "            'properties_is_ort': False,\n",
      "            'properties_is_quantized': False,\n",
      "            'properties_is_sparse': False,\n",
      "            'properties_is_sparse_csr': False,\n",
      "            'properties_is_vulkan': False,\n",
      "            'properties_is_xla': False,\n",
      "            'properties_is_xpu': False,\n",
      "            'properties_itemsize': 2,\n",
      "            'properties_name': None,\n",
      "            'properties_names': [None],\n",
      "            'properties_nbytes': 128,\n",
      "            'properties_ndim': 1,\n",
      "            'properties_output_nr': 0,\n",
      "            'properties_partition_dim': 0,\n",
      "            'properties_partition_stride': 1,\n",
      "            'properties_requires_grad': True,\n",
      "            'properties_retains_grad': False,\n",
      "            'properties_shape': [64],\n",
      "            'properties_tensor_model_parallel': True}}\n"
     ]
    }
   ],
   "source": [
    "def construct_states(initial_state, changes):\n",
    "    # change \"param\" to \"value\" for consistency\n",
    "    if 'param' in initial_state:\n",
    "        initial_state['value'] = initial_state['param']\n",
    "        del initial_state['param']\n",
    "    \n",
    "    states = [initial_state]\n",
    "    for i, trace in changes.iterrows():\n",
    "        state = states[-1].copy()\n",
    "        if 'properties' in trace.change:\n",
    "            state['properties'] = trace.change['properties']['new']\n",
    "        if 'value' in trace.change:\n",
    "            state['value'] = trace.change['value']['new']\n",
    "        states.append(state)\n",
    "    return states\n",
    "\n",
    "layer = 'module.3.mlp.dense_h_to_4h.bias'\n",
    "state_changes = traces_by_name[layer]\n",
    "initial_state = None\n",
    "for param in trace_state_dump.iloc[0].state:\n",
    "    if param['name'] == layer:\n",
    "        initial_state = param\n",
    "        break\n",
    "assert initial_state is not None\n",
    "states = construct_states(initial_state, state_changes)\n",
    "vi = VariableInstance(layer, torch.nn.Parameter, states)\n",
    "inv_single = SingleInvariantConstant(vi)\n",
    "pprint(inv_single.get_invariant_properties(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: layer module.3.input_layernorm.weight has 1 state changes\n",
      "Warning: layer module.3.post_attention_layernorm.weight has 1 state changes\n",
      "Warning: layer module.4.input_layernorm.weight has 1 state changes\n",
      "Warning: layer module.4.post_attention_layernorm.weight has 1 state changes\n",
      "Warning: layer module.5.input_layernorm.weight has 1 state changes\n",
      "Warning: layer module.5.post_attention_layernorm.weight has 1 state changes\n",
      "Warning: layer module.6.input_layernorm.weight has 1 state changes\n",
      "Warning: layer module.6.post_attention_layernorm.weight has 1 state changes\n",
      "Warning: layer module.8.weight has 1 state changes\n",
      "{ 'consistent': [ 'properties_is_cpu',\n",
      "                  'properties_is_ipu',\n",
      "                  'properties_is_sparse_csr',\n",
      "                  'properties__base',\n",
      "                  'properties_is_xla',\n",
      "                  'properties_is_quantized',\n",
      "                  'properties_partition_stride',\n",
      "                  'properties_is_xpu',\n",
      "                  'properties_itemsize',\n",
      "                  'properties_ds_pipe_replicated',\n",
      "                  'properties_is_sparse',\n",
      "                  'properties_is_ort',\n",
      "                  'properties__backward_hooks',\n",
      "                  'properties_is_mtia',\n",
      "                  'properties__has_symbolic_sizes_strides',\n",
      "                  'properties_is_nested',\n",
      "                  'properties_grad_fn',\n",
      "                  'properties_name',\n",
      "                  'properties__python_dispatch',\n",
      "                  'properties_retains_grad',\n",
      "                  'properties_is_vulkan',\n",
      "                  'properties__grad_fn',\n",
      "                  'properties_is_meta',\n",
      "                  'properties_is_cuda',\n",
      "                  'properties_output_nr',\n",
      "                  'properties__post_accumulate_grad_hooks',\n",
      "                  'properties_requires_grad',\n",
      "                  'properties_is_mkldnn',\n",
      "                  'properties_is_mps',\n",
      "                  'properties_is_leaf']}\n"
     ]
    }
   ],
   "source": [
    "# layer = 'module.3.mlp.dense_h_to_4h.bias'\n",
    "variable_instances = []\n",
    "for layer in traces_by_name.keys():\n",
    "    state_changes = traces_by_name[layer]\n",
    "    initial_state = None\n",
    "    for param in trace_state_dump.iloc[0].state:\n",
    "        if param['name'] == layer:\n",
    "            initial_state = param\n",
    "            break\n",
    "    assert initial_state is not None\n",
    "    if len(state_changes) != 23:\n",
    "        print(\"Warning: layer {} has {} state changes\".format(layer, len(state_changes)))\n",
    "        continue\n",
    "    states = construct_states(initial_state, state_changes)\n",
    "    vi = VariableInstance(layer, torch.nn.Parameter, states)\n",
    "    variable_instances.append(vi)\n",
    "inv_multi = MultiInvariantConsistency(variable_instances)\n",
    "pprint(inv_multi.get_invariant_properties(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2118043/2118043 [00:23<00:00, 89995.06it/s] \n",
      "100%|██████████| 2133353/2133353 [00:24<00:00, 87809.66it/s] \n",
      "100%|██████████| 2133929/2133929 [00:23<00:00, 90957.33it/s] \n",
      "100%|██████████| 2181870/2181870 [00:25<00:00, 84449.45it/s] \n",
      "100%|██████████| 2133353/2133353 [00:22<00:00, 93237.01it/s] \n",
      "100%|██████████| 2120961/2120961 [00:26<00:00, 80733.70it/s] \n",
      "100%|██████████| 2118235/2118235 [00:25<00:00, 82906.59it/s] \n",
      "100%|██████████| 2160262/2160262 [00:26<00:00, 80552.52it/s] \n"
     ]
    }
   ],
   "source": [
    "import os, sys, tqdm, json, pandas as pd\n",
    "\n",
    "# trace loading process\n",
    "path_to_traces = \"/home/yuxuan/Megatron-DeepSpeed/experiments/toy-ml-daikon-auto-syncing\"\n",
    "\n",
    "trace_paths = [os.path.join(path_to_traces, f) for f in os.listdir(path_to_traces) if f.endswith(\"_trace.log\")]\n",
    "\n",
    "keyword = \"layernorm.bias\"\n",
    "\n",
    "def get_process_id_from_trace_path(trace_path):\n",
    "    return os.path.basename(trace_path).split(\"_\")[0]\n",
    "\n",
    "trace_by_process_id = {}\n",
    "for trace_path in trace_paths:\n",
    "    process_id = get_process_id_from_trace_path(trace_path)\n",
    "    with open(trace_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    traces = []\n",
    "    for trace in tqdm.tqdm(lines):\n",
    "        if not trace.startswith(\"{\"):\n",
    "            # heuristics to skip non-json lines\n",
    "            continue\n",
    "        try:\n",
    "            traces.append(json.loads(trace))\n",
    "        except:\n",
    "            print(trace)\n",
    "            raise\n",
    "    traces_df = pd.DataFrame(traces)\n",
    "    traces_state_change = traces_df[(traces_df[\"type\"] == \"state_change\")]\n",
    "    trace_state_dump = traces_df[(traces_df[\"type\"] == \"state_dump\")]\n",
    "    # split the traces by name\n",
    "    traces_by_name = {}\n",
    "    for name, group in traces_state_change.groupby(\"name\"):\n",
    "        traces_by_name[name] = group.reset_index(drop=True)\n",
    "    trace_by_process_id[process_id] = {\n",
    "        \"original_state_dump\": trace_state_dump,\n",
    "        \"traces_by_name\": traces_by_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.3.input_layernorm.bias 8\n",
      "{ 'consistent': [ '_PIPELINE_MODEL_PARALLEL_GROUP_YUXUAN_RANK',\n",
      "                  '_VIRTUAL_PIPELINE_MODEL_PARALLEL_RANK',\n",
      "                  '_MPU_TENSOR_MODEL_PARALLEL_RANK',\n",
      "                  '_EMBEDDING_GROUP_YUXUAN_RANK',\n",
      "                  '_MPU_PIPELINE_MODEL_PARALLEL_RANK',\n",
      "                  '_DATA_PARALLEL_GROUP_YUXUAN_RANK']}\n",
      "_PIPELINE_MODEL_PARALLEL_GROUP_YUXUAN_RANK 0\n",
      "_VIRTUAL_PIPELINE_MODEL_PARALLEL_RANK None\n",
      "_MPU_TENSOR_MODEL_PARALLEL_RANK None\n",
      "_EMBEDDING_GROUP_YUXUAN_RANK 0\n",
      "_MPU_PIPELINE_MODEL_PARALLEL_RANK None\n",
      "_DATA_PARALLEL_GROUP_YUXUAN_RANK 1\n",
      "dict_keys(['thread_id', 'process_id', '_TENSOR_MODEL_PARALLEL_GROUP_YUXUAN_RANK', '_PIPELINE_MODEL_PARALLEL_GROUP_YUXUAN_RANK', '_MODEL_PARALLEL_GROUP_YUXUAN_RANK', '_EMBEDDING_GROUP_YUXUAN_RANK', '_DATA_PARALLEL_GROUP_YUXUAN_RANK', '_VIRTUAL_PIPELINE_MODEL_PARALLEL_RANK', '_MPU_TENSOR_MODEL_PARALLEL_RANK', '_MPU_PIPELINE_MODEL_PARALLEL_RANK', '_PIPELINE_GLOBAL_RANKS'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Let's select the relevant layers with `keyword` and construct the variable instances\n",
    "We are going to apply multi-invariant consistency checking on each of these layer across all processes\n",
    "\"\"\"\n",
    "\n",
    "def construct_states(initial_state, changes):\n",
    "    # change \"param\" to \"value\" for consistency\n",
    "    if 'param' in initial_state:\n",
    "        initial_state['value'] = initial_state['param']\n",
    "        del initial_state['param']\n",
    "    \n",
    "    states = [initial_state]\n",
    "    for i, trace in changes.iterrows():\n",
    "        state = states[-1].copy()\n",
    "        if 'properties' in trace.change:\n",
    "            state['properties'] = trace.change['properties']['new']\n",
    "        if 'value' in trace.change:\n",
    "            state['value'] = trace.change['value']['new']\n",
    "        states.append(state)\n",
    "    return states\n",
    "\n",
    "variable_instances = {}\n",
    "for process_id, trace in trace_by_process_id.items():\n",
    "    traces_by_name = trace[\"traces_by_name\"]\n",
    "    original_state_dump = trace[\"original_state_dump\"]\n",
    "    for name in traces_by_name.keys():\n",
    "        if keyword in name:\n",
    "            state_changes = traces_by_name[name]\n",
    "            initial_state = None\n",
    "            for param in original_state_dump.iloc[0].state:\n",
    "                if param['name'] == name:\n",
    "                    initial_state = param\n",
    "                    break\n",
    "            assert initial_state is not None\n",
    "            if len(state_changes) != 23:\n",
    "                print(\"Warning: layer {} has {} state changes\".format(name, len(state_changes)))\n",
    "                continue\n",
    "            states = construct_states(initial_state, state_changes)\n",
    "            vi = VariableInstance(name, torch.nn.Parameter, states, len(states) * [traces_by_name['module.3.input_layernorm.bias'].meta_vars.iloc[0]])\n",
    "            if name not in variable_instances:\n",
    "                variable_instances[name] = []\n",
    "            variable_instances[name].append(vi)\n",
    "\n",
    "for name, vis in variable_instances.items():\n",
    "    print(name, len(vis))\n",
    "    inv_multi = MultiInvariantConsistency(vis[5:-1])\n",
    "    # pprint(inv_multi.get_invariant_properties(), indent=2)\n",
    "    pprint(inv_multi.find_preconditions(), indent=2)\n",
    "    pre_conds = inv_multi.find_preconditions()\n",
    "    for pre_cond in pre_conds['consistent']:\n",
    "        print(pre_cond, traces_by_name[name].meta_vars.iloc[0][pre_cond])\n",
    "    print(traces_by_name[name].meta_vars.iloc[0].keys())\n",
    "\n",
    "    assert 'value' in inv_multi.get_invariant_properties()['consistent']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(traces_by_name['module.3.input_layernorm.bias'].meta_vars.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * [1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeed-yuxuan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
