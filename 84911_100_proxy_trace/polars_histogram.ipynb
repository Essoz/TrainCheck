{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yijun/ml-daikon/mldaikon\n",
      "['/home/yijun/ml-daikon/mldaikon/collect_trace.py', '/home/yijun/ml-daikon/mldaikon/infer_engine.py', '/home/yijun/ml-daikon/mldaikon/utils.py', '/home/yijun/ml-daikon/mldaikon/__init__.py', '/home/yijun/ml-daikon/mldaikon/invariant/base_cls.py', '/home/yijun/ml-daikon/mldaikon/invariant/relation_pool.py', '/home/yijun/ml-daikon/mldaikon/invariant/precondition.py', '/home/yijun/ml-daikon/mldaikon/invariant/__init__.py', '/home/yijun/ml-daikon/mldaikon/invariant/contain_relation.py', '/home/yijun/ml-daikon/mldaikon/invariant/periodicity_relation.py', '/home/yijun/ml-daikon/mldaikon/invariant/consistency_relation.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/dumper.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_basics.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/utils.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_handler.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/torch_proxy.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/__init__.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_methods.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_observer.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/config.py', '/home/yijun/ml-daikon/mldaikon/trace/types.py', '/home/yijun/ml-daikon/mldaikon/trace/trace.py', '/home/yijun/ml-daikon/mldaikon/config/__init__.py', '/home/yijun/ml-daikon/mldaikon/config/config.py', '/home/yijun/ml-daikon/mldaikon/runner/runner.py', '/home/yijun/ml-daikon/mldaikon/runner/__init__.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/variable.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/tracer.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/__init__.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/replace_functions.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/source_file.py', '/home/yijun/ml-daikon/mldaikon/static_analyzer/call_graph_parser.py']\n",
      "auto observer enabled with observing depth:  5\n",
      "observe up to the depth of the function call\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.LinearLR'>\n",
      "Observe function: register_step_post_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: zero_grad found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: ema_update found in module: <function get_ema_avg_fn at 0x7fc795c93250>\n",
      "Observe function: update_group found in module: <function Optimizer.load_state_dict at 0x7fc795c41990>\n",
      "Observe function: get_swa_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: step found in module: <class 'torch.optim.adagrad.Adagrad'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.CosineAnnealingLR'>\n",
      "Observe function: swa_update found in module: <function get_swa_avg_fn at 0x7fc793b6ed40>\n",
      "Observe function: update_bn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.MultiplicativeLR'>\n",
      "Observe function: get_swa_multi_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: ema_update found in module: <function get_ema_multi_avg_fn at 0x7fc795c93130>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.MultiplicativeLR'>\n",
      "Observe function: forward found in module: <class 'torch.optim.swa_utils.AveragedModel'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
      "Observe function: share_memory found in module: <class 'torch.optim.adagrad.Adagrad'>\n",
      "Observe function: update_parameters found in module: <class 'torch.optim.swa_utils.AveragedModel'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.ConstantLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.OneCycleLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.ChainedScheduler'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.ChainedScheduler'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: adadelta found in module: <module 'torch.optim.adadelta' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adadelta.py'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.ChainedScheduler'>\n",
      "Observe function: adagrad found in module: <module 'torch.optim.adagrad' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adagrad.py'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.swa_utils.SWALR'>\n",
      "Observe function: adam found in module: <module 'torch.optim.adam' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adam.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.SequentialLR'>\n",
      "Observe function: adamw found in module: <module 'torch.optim.adamw' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adamw.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.lbfgs.LBFGS'>\n",
      "Observe function: asgd found in module: <module 'torch.optim.asgd' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/asgd.py'>\n",
      "Observe function: register_step_pre_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: radam found in module: <module 'torch.optim.radam' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/radam.py'>\n",
      "Observe function: nadam found in module: <module 'torch.optim.nadam' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/nadam.py'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: register_optimizer_step_post_hook found in module: <module 'torch.optim.optimizer' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/optimizer.py'>\n",
      "Observe function: rmsprop found in module: <module 'torch.optim.rmsprop' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/rmsprop.py'>\n",
      "Observe function: sgd found in module: <module 'torch.optim.sgd' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/sgd.py'>\n",
      "Observe function: adamax found in module: <module 'torch.optim.adamax' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adamax.py'>\n",
      "Observe function: register_optimizer_step_pre_hook found in module: <module 'torch.optim.optimizer' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/optimizer.py'>\n",
      "Observe function: register_state_dict_pre_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: print_lr found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: step found in module: <class 'torch.optim.adam.Adam'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.LambdaLR'>\n",
      "Observe function: get_last_lr found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: in_cooldown found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: rprop found in module: <module 'torch.optim.rprop' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/rprop.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: step found in module: <class 'torch.optim.radam.RAdam'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: is_better found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: step found in module: <class 'torch.optim.nadam.NAdam'>\n",
      "Observe function: step found in module: <class 'torch.optim.adamax.Adamax'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.LambdaLR'>\n",
      "Observe function: step found in module: <class 'torch.optim.rprop.Rprop'>\n",
      "Observe function: register_state_dict_post_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: step found in module: <class 'torch.optim.asgd.ASGD'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.LambdaLR'>\n",
      "Observe function: get_ema_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: swa_update found in module: <function get_swa_multi_avg_fn at 0x7fc793b6f370>\n",
      "Observe function: scale_fn found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.SequentialLR'>\n",
      "Observe function: get_ema_multi_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: add_param_group found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.SequentialLR'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.MultiplicativeLR'>\n",
      "Observe function: step found in module: <class 'torch.optim.adamw.AdamW'>\n",
      "Observe function: step found in module: <class 'torch.optim.adadelta.Adadelta'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.MultiStepLR'>\n",
      "Observe function: register_load_state_dict_post_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.StepLR'>\n",
      "Observe function: register_load_state_dict_pre_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'>\n",
      "Observe function: pack_group found in module: <function Optimizer.state_dict at 0x7fc793b6feb0>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'>\n",
      "Observe function: wrapper found in module: <function Optimizer.profile_hook_step at 0x7fc795c411b0>\n",
      "Observe function: obj_func found in module: <function LBFGS.step at 0x7fc793b884c0>\n",
      "Observe function: step found in module: <class 'torch.optim.sgd.SGD'>\n",
      "Observe function: step found in module: <class 'torch.optim.sparse_adam.SparseAdam'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "function column not found in the events, no function related invariants will be extracted.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "from mldaikon.trace.trace import read_trace_file\n",
    "import os\n",
    "files = [x for x in os.listdir() if \"API\" in x] + [x for x in os.listdir() if \"_trace_processed_\" in x]\n",
    "traces = read_trace_file(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = traces.events.filter(\n",
    "    pl.col(\"var_name\")==\"_fc.weight\"\n",
    ").select(\n",
    "    pl.col([\"time\",\"attributes.grad\"])\n",
    ") #.sort(\"time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.0000000': [1720406960.8149204, 1720406971.4680138, 1720406976.7049508, 1720406979.346858, 1720406982.0283363, 1720406984.73768, 1720406987.5116575, 1720406990.3619044, 1720406993.4950294, 1720406997.0083642, 1720406999.6950912, 1720407002.461145, 1720407005.1643226, 1720407007.895734, 1720407010.626812, 1720407013.4521222, 1720407016.9164438, 1720407020.4590948, 1720407024.0115213, 1720407027.6551113, 1720407031.4432862, 1720407035.2597826, 1720407038.9161868, 1720407041.5943751, 1720407044.2830236, 1720407046.938165, 1720407049.627383, 1720407052.3574166, 1720407055.0834103, 1720407057.8249745, 1720407060.5239766, 1720407063.2911618, 1720407066.0274982, 1720407068.9941866, 1720407072.1648195, 1720407074.863804, 1720407077.5564609, 1720407080.2651334, 1720407083.632197, 1720407087.1064472, 1720407089.8199298, 1720407092.5497298, 1720407095.9125953, 1720407099.3964503, 1720407102.0816019, 1720407104.755465, 1720407107.4855378, 1720407110.1374605, 1720407113.4704459, 1720407116.8999863, 1720407119.569047, 1720407122.271738, 1720407125.0224504, 1720407128.5301034, 1720407132.2250743, 1720407135.912865, 1720407139.465438, 1720407143.1336179, 1720407146.7060492, 1720407150.3650339, 1720407153.82201, 1720407156.7921636, 1720407160.3360858, 1720407163.9567468, 1720407167.552755, 1720407170.7358413, 1720407173.4040654, 1720407176.0827386, 1720407179.7475016, 1720407183.3577418, 1720407186.886297, 1720407190.2400525, 1720407192.9236455, 1720407195.665251, 1720407199.1418688, 1720407202.260923, 1720407204.9699728, 1720407207.6937442, 1720407210.4085486, 1720407213.3345034, 1720407216.759735, 1720407219.453567, 1720407222.3189838, 1720407225.9241354, 1720407229.1654596, 1720407231.9079251, 1720407235.4906254, 1720407239.034474, 1720407242.3980992, 1720407245.1097438, 1720407247.8503823, 1720407250.5909803, 1720407253.2606843, 1720407256.0876267, 1720407258.8953953, 1720407261.6621392, 1720407264.5290835, 1720407268.1656125], '1.4694553': [1720406975.0456471, 1720406975.452999], '1.5725378': [1720406977.815351, 1720406978.1755042], '1.5125565': [1720406980.4965043, 1720406980.8681755], '1.7505934': [1720406983.1834905, 1720406983.5489862], '1.6168348': [1720406985.900211, 1720406986.2688322], '1.5791478': [1720406988.6749346, 1720406989.0493925], '1.6354960': [1720406991.5235152, 1720406991.9010632], '1.4940678': [1720406994.88662, 1720406995.418916], '1.5861053': [1720406998.1072853, 1720406998.464919], '1.4619365': [1720407000.8408241, 1720407001.216724], '1.5442382': [1720407003.5881615, 1720407003.9446008], '1.6142274': [1720407006.2908616, 1720407006.6607966], '1.4754765': [1720407009.0259972, 1720407009.3921967], '1.4712704': [1720407011.7868466, 1720407012.1638844], '1.4910915': [1720407014.83286, 1720407015.363235], '1.5203110': [1720407018.298733, 1720407018.830633], '1.5437763': [1720407021.8857014, 1720407022.4191365], '1.5159822': [1720407025.4394758, 1720407025.9735677], '1.5108239': [1720407029.0753176, 1720407029.6109416], '1.4943447': [1720407032.8912427, 1720407033.4453125], '1.5292604': [1720407036.6802964, 1720407037.2246509], '1.5088862': [1720407040.0729442, 1720407040.4315047], '1.5123320': [1720407042.7430575, 1720407043.1166596], '1.5160279': [1720407045.4024065, 1720407045.7843888], '1.5185888': [1720407048.0564675, 1720407048.4324489], '1.5138889': [1720407050.752745, 1720407051.1188076], '1.5067986': [1720407053.4753664, 1720407053.8422859], '1.5377758': [1720407056.2216594, 1720407056.5869727], '1.5094013': [1720407058.9554923, 1720407059.3186057], '1.5253796': [1720407061.7322888, 1720407062.1018295], '1.4442332': [1720407064.4134607, 1720407064.7808852], '1.4849243': [1720407067.184918, 1720407067.5681584], '1.4620898': [1720407070.4011374, 1720407070.9504516], '1.4885104': [1720407073.2920635, 1720407073.6787405], '1.5429522': [1720407076.0041952, 1720407076.3649514], '1.5340154': [1720407078.6788723, 1720407079.0717506], '1.4842138': [1720407081.440456, 1720407081.9758482], '1.4931786': [1720407085.1203218, 1720407085.6588178], '1.4836499': [1720407088.2221513, 1720407088.5902786], '1.5023108': [1720407090.9793653, 1720407091.3465414], '1.5286767': [1720407093.7985928, 1720407094.3381004], '1.4963718': [1720407097.3010516, 1720407097.8377469], '1.5726792': [1720407100.5259323, 1720407100.8989046], '1.5150831': [1720407103.2272868, 1720407103.5964613], '1.5358376': [1720407105.919093, 1720407106.2884076], '1.4682148': [1720407108.5821655, 1720407108.9479196], '1.4723868': [1720407111.4566498, 1720407112.031626], '1.4472522': [1720407114.9496255, 1720407115.4906414], '1.5495045': [1720407118.031543, 1720407118.3905365], '1.5180128': [1720407120.694114, 1720407121.0609229], '1.4946232': [1720407123.3918822, 1720407123.7592025], '1.4211708': [1720407126.3407128, 1720407126.8791451], '1.4943489': [1720407130.0941582, 1720407130.634333], '1.4425755': [1720407133.6797683, 1720407134.216795], '1.4853833': [1720407137.3656511, 1720407137.9093406], '1.4769031': [1720407140.947485, 1720407141.4855492], '1.4743078': [1720407144.5150955, 1720407145.0505464], '1.5477572': [1720407148.171451, 1720407148.7072105], '1.4152781': [1720407151.7575986, 1720407152.2977357], '1.4723933': [1720407154.9533627, 1720407155.3177392], '1.3634834': [1720407158.1878057, 1720407158.7329288], '1.5034390': [1720407161.7738307, 1720407162.314341], '1.5504964': [1720407165.3527205, 1720407165.8928225], '1.4769540': [1720407168.9418776, 1720407169.478908], '1.4266255': [1720407171.875464, 1720407172.2374945], '1.4404950': [1720407174.5458617, 1720407174.9115229], '1.5090198': [1720407177.5594535, 1720407178.1071117], '1.4766450': [1720407181.152458, 1720407181.6922507], '1.4914447': [1720407184.763579, 1720407185.3013008], '1.4980574': [1720407188.2690988, 1720407188.8072383], '1.4616459': [1720407191.345204, 1720407191.7097156], '1.4479403': [1720407194.0573354, 1720407194.421355], '1.3790110': [1720407196.9490366, 1720407197.4847176], '1.4271092': [1720407200.5296464, 1720407201.039624], '1.4190291': [1720407203.373648, 1720407203.7389145], '1.4958963': [1720407206.0979328, 1720407206.4532406], '1.4171096': [1720407208.7931054, 1720407209.1862602], '1.4882913': [1720407211.5148625, 1720407211.8849022], '1.4704289': [1720407214.7306614, 1720407215.27487], '1.4729896': [1720407217.870312, 1720407218.2291672], '1.4715511': [1720407220.619257, 1720407220.9922152], '1.5127830': [1720407223.705465, 1720407224.2449546], '1.4352645': [1720407227.4082508, 1720407227.9497135], '1.4988695': [1720407230.3186073, 1720407230.7041008], '1.5413381': [1720407233.2933395, 1720407233.8520205], '1.5836247': [1720407236.8761458, 1720407237.415258], '1.4412864': [1720407240.465462, 1720407241.0226188], '1.4706913': [1720407243.5370612, 1720407243.9037435], '1.4743224': [1720407246.2973716, 1720407246.6664405], '1.4970110': [1720407248.9961538, 1720407249.3602552], '1.4655909': [1720407251.7422566, 1720407252.1150136], '1.5591057': [1720407254.4721649, 1720407254.842919], '1.5167717': [1720407257.22995, 1720407257.6037333], '1.4684442': [1720407260.007588, 1720407260.3835382], '1.4261583': [1720407262.7661273, 1720407263.1467602], '1.4425554': [1720407265.9446034, 1720407266.494006]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "histo_log = {}\n",
    "\n",
    "for row in grads.iter_rows(named=True):\n",
    "    if row['attributes.grad']:\n",
    "        grad = f\"{np.linalg.norm(row['attributes.grad']):.7f}\"\n",
    "    else:\n",
    "        grad = f\"{0:.7f}\"\n",
    "    if grad in histo_log:\n",
    "        histo_log[grad].append(row['time'])\n",
    "    else:\n",
    "        histo_log[grad] = [row['time']]\n",
    "        \n",
    "# print(histo_log)\n",
    "# for grad, times in histo_log.items():\n",
    "#     times_difference = [times[i] - times[i-1] for i in range(1, len(times))]\n",
    "#     histo_log[grad] = times_difference\n",
    "print(histo_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(histo_log['0.0000000']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
