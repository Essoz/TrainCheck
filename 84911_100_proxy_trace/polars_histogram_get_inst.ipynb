{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yijun/ml-daikon/mldaikon\n",
      "['/home/yijun/ml-daikon/mldaikon/collect_trace.py', '/home/yijun/ml-daikon/mldaikon/infer_engine.py', '/home/yijun/ml-daikon/mldaikon/utils.py', '/home/yijun/ml-daikon/mldaikon/__init__.py', '/home/yijun/ml-daikon/mldaikon/invariant/var_periodic_change_relation.py', '/home/yijun/ml-daikon/mldaikon/invariant/base_cls.py', '/home/yijun/ml-daikon/mldaikon/invariant/relation_pool.py', '/home/yijun/ml-daikon/mldaikon/invariant/precondition.py', '/home/yijun/ml-daikon/mldaikon/invariant/__init__.py', '/home/yijun/ml-daikon/mldaikon/invariant/contain_relation.py', '/home/yijun/ml-daikon/mldaikon/invariant/consistency_relation.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/dumper.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_basics.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/utils.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_handler.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/torch_proxy.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/__init__.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_methods.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/proxy_observer.py', '/home/yijun/ml-daikon/mldaikon/proxy_wrapper/config.py', '/home/yijun/ml-daikon/mldaikon/trace/types.py', '/home/yijun/ml-daikon/mldaikon/trace/trace.py', '/home/yijun/ml-daikon/mldaikon/config/__init__.py', '/home/yijun/ml-daikon/mldaikon/config/config.py', '/home/yijun/ml-daikon/mldaikon/runner/runner.py', '/home/yijun/ml-daikon/mldaikon/runner/__init__.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/variable.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/tracer.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/__init__.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/replace_functions.py', '/home/yijun/ml-daikon/mldaikon/instrumentor/source_file.py', '/home/yijun/ml-daikon/mldaikon/static_analyzer/call_graph_parser.py']\n",
      "auto observer enabled with observing depth:  3\n",
      "observe up to the depth of the function call\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.LinearLR'>\n",
      "Observe function: register_step_post_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: zero_grad found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: ema_update found in module: <function get_ema_avg_fn at 0x7f3b075a3370>\n",
      "Observe function: get_swa_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: step found in module: <class 'torch.optim.adagrad.Adagrad'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.CosineAnnealingLR'>\n",
      "Observe function: update_bn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.MultiplicativeLR'>\n",
      "Observe function: get_swa_multi_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: ema_update found in module: <function get_ema_multi_avg_fn at 0x7f3b075a3250>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.MultiplicativeLR'>\n",
      "Observe function: forward found in module: <class 'torch.optim.swa_utils.AveragedModel'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
      "Observe function: share_memory found in module: <class 'torch.optim.adagrad.Adagrad'>\n",
      "Observe function: update_parameters found in module: <class 'torch.optim.swa_utils.AveragedModel'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.ConstantLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.OneCycleLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.ChainedScheduler'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.ChainedScheduler'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: adadelta found in module: <module 'torch.optim.adadelta' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adadelta.py'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.ChainedScheduler'>\n",
      "Observe function: adagrad found in module: <module 'torch.optim.adagrad' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adagrad.py'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.swa_utils.SWALR'>\n",
      "Observe function: adam found in module: <module 'torch.optim.adam' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adam.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.SequentialLR'>\n",
      "Observe function: adamw found in module: <module 'torch.optim.adamw' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adamw.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.lbfgs.LBFGS'>\n",
      "Observe function: asgd found in module: <module 'torch.optim.asgd' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/asgd.py'>\n",
      "Observe function: register_step_pre_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: radam found in module: <module 'torch.optim.radam' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/radam.py'>\n",
      "Observe function: nadam found in module: <module 'torch.optim.nadam' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/nadam.py'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: register_optimizer_step_post_hook found in module: <module 'torch.optim.optimizer' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/optimizer.py'>\n",
      "Observe function: rmsprop found in module: <module 'torch.optim.rmsprop' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/rmsprop.py'>\n",
      "Observe function: sgd found in module: <module 'torch.optim.sgd' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/sgd.py'>\n",
      "Observe function: adamax found in module: <module 'torch.optim.adamax' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/adamax.py'>\n",
      "Observe function: register_optimizer_step_pre_hook found in module: <module 'torch.optim.optimizer' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/optimizer.py'>\n",
      "Observe function: register_state_dict_pre_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: print_lr found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: step found in module: <class 'torch.optim.adam.Adam'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.LambdaLR'>\n",
      "Observe function: get_last_lr found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: in_cooldown found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: rprop found in module: <module 'torch.optim.rprop' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/rprop.py'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: step found in module: <class 'torch.optim.radam.RAdam'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.LRScheduler'>\n",
      "Observe function: is_better found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: step found in module: <class 'torch.optim.nadam.NAdam'>\n",
      "Observe function: step found in module: <class 'torch.optim.adamax.Adamax'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.LambdaLR'>\n",
      "Observe function: step found in module: <class 'torch.optim.rprop.Rprop'>\n",
      "Observe function: register_state_dict_post_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "Observe function: step found in module: <class 'torch.optim.asgd.ASGD'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.LambdaLR'>\n",
      "Observe function: get_ema_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: scale_fn found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.SequentialLR'>\n",
      "Observe function: get_ema_multi_avg_fn found in module: <module 'torch.optim.swa_utils' from '/home/yijun/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py'>\n",
      "Observe function: add_param_group found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.SequentialLR'>\n",
      "Observe function: state_dict found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: load_state_dict found in module: <class 'torch.optim.lr_scheduler.CyclicLR'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.MultiplicativeLR'>\n",
      "Observe function: step found in module: <class 'torch.optim.adamw.AdamW'>\n",
      "Observe function: step found in module: <class 'torch.optim.adadelta.Adadelta'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.MultiStepLR'>\n",
      "Observe function: register_load_state_dict_post_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.StepLR'>\n",
      "Observe function: register_load_state_dict_pre_hook found in module: <class 'torch.optim.optimizer.Optimizer'>\n",
      "Observe function: get_lr found in module: <class 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'>\n",
      "Observe function: step found in module: <class 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'>\n",
      "Observe function: wrapper found in module: <function Optimizer.profile_hook_step at 0x7f3b075512d0>\n",
      "Observe function: obj_func found in module: <function LBFGS.step at 0x7f3b0549c430>\n",
      "Observe function: step found in module: <class 'torch.optim.sgd.SGD'>\n",
      "Observe function: step found in module: <class 'torch.optim.sparse_adam.SparseAdam'>\n",
      "['proxy_trace_processed_2.json', 'proxy_trace_processed_0.json', 'proxy_trace_processed_1.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "function column not found in the events, no function related invariants will be extracted.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from mldaikon.trace.trace import read_trace_file\n",
    "import os\n",
    "\n",
    "files = [x for x in os.listdir() if \"_trace_processed_\" in x]\n",
    "print(files)\n",
    "\n",
    "\n",
    "traces = read_trace_file(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Variable Instances: 100%|██████████| 215/215 [00:08<00:00, 24.12it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var_inst = traces.get_var_insts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "histo_log = {}\n",
    "for var_id, attr in var_inst.items():\n",
    "    if var_id.var_name == \"_fc.weight\":\n",
    "        for attr_grad in attr['grad']:\n",
    "            if attr_grad.value:\n",
    "                grad = f\"{np.linalg.norm(attr_grad.value):.7f}\"\n",
    "            else:\n",
    "                grad = \"\"   # if the attribute is None, \n",
    "            if grad in histo_log:\n",
    "                histo_log[grad] += 1\n",
    "            else:\n",
    "                histo_log[grad] = 1\n",
    "print(histo_log[''])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
